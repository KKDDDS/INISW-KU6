{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b624b8e8-57de-448b-b81a-b76bd09681fb",
   "metadata": {},
   "source": [
    "repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad2b8ef-c703-4c33-abdc-87730e571152",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06e5d29-096d-4595-a6fd-bddc669a7acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "926a6e2b-2d3a-4b23-ae95-818b451040ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bb72ea2-045e-4130-b196-15f07dadb745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S:\n",
    "    def __repr__(self):\n",
    "        return 'repr'\n",
    "    def __str__(self):\n",
    "        return 'str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55dbe299-74e3-498e-8068-f89f774dfa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = S()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa451e28-c7ed-4500-b01b-5efe6b18563f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repr"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s #자기 자신 프린트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2192a1c7-26ec-4ee1-8f85-9f3b9b39c082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str\n"
     ]
    }
   ],
   "source": [
    "print(s) #다른값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a60e539a-0b37-4532-9cdc-c22b1faad8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54ad0bda-03ee-4ace-b83a-434620898911",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b427de13-1db5-46ba-87ba-6eebd82fc30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "719a3fdf-1b2f-4667-a270-9bddf396f675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d3977cb-c37c-4ae2-b344-69ce8f820603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(fun):\n",
    "    #@wraps(fun)\n",
    "    def xx(*a, **b):\n",
    "        print('d')\n",
    "        fun(*a, **b)\n",
    "    return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6189ec9-dd2f-4f48-b68b-e8f9b9f47991",
   "metadata": {},
   "outputs": [],
   "source": [
    "@x\n",
    "def t():\n",
    "    print('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04ee6125-81b7-44ab-88d5-471bc4f0fbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.x.<locals>.xx(*a, **b)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a680558-ddea-473d-bde7-8e10a5d98f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function x.<locals>.xx at 0x000001EF81D8A680>\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff99144f-e1fc-4e36-8399-2288540c6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow는 괄호가 있지만 삼중 구조가 아님\n",
    "#인자를 decorator로 받을 수 있다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a5c9671-d3ba-489d-9267-7828e357dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77668b1b-ccf2-4a14-b5c5-26bde9334e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6efe149-5de5-4581-b881-94525dfc75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13b00c47-48e5-4e00-8aa3-4e68a87a4b51",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add expected 2 arguments, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: add expected 2 arguments, got 1"
     ]
    }
   ],
   "source": [
    "add(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d088954f-8a13-46c6-9f16-a13bea626b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = partial(add,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f745b29-b4c3-4a6f-b281-39b10f62281a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf7ea386-ad8c-4f60-9b13-9fec339ef3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04c6da58-3389-48a1-a121-90eb2ef8d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "705321ca-b9ab-47f9-b115-f6184bdf7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tf_export(\"function\")\n",
      "@deprecation.deprecated_args(None,\n",
      "                             \"experimental_compile is deprecated, use \"\n",
      "                             \"jit_compile instead\", \"experimental_compile\")\n",
      "@deprecation.deprecated_args(None,\n",
      "                             \"experimental_relax_shapes is deprecated, use \"\n",
      "                             \"reduce_retracing instead\",\n",
      "                             \"experimental_relax_shapes\")\n",
      "@deprecation.deprecated_args(None,\n",
      "                             \"experimental_follow_type_hints is deprecated\",\n",
      "                             \"experimental_follow_type_hints\")\n",
      "def function(\n",
      "    func=None,\n",
      "    input_signature=None,\n",
      "    autograph=True,\n",
      "    jit_compile=None,\n",
      "    reduce_retracing=False,\n",
      "    experimental_implements=None,\n",
      "    experimental_autograph_options=None,\n",
      "    experimental_relax_shapes=None,\n",
      "    experimental_compile=None,\n",
      "    experimental_follow_type_hints=None  # pylint: disable=unused-argument\n",
      ") -> core.GenericFunction:\n",
      "  \"\"\"Compiles a function into a callable TensorFlow graph.\n",
      "\n",
      "  `tf.function` constructs a `tf.types.experimental.GenericFunction` that\n",
      "  executes a TensorFlow graph (`tf.Graph`) created by trace-compiling the\n",
      "  TensorFlow operations in `func`. More information on the topic can be found\n",
      "  in [Introduction to Graphs and tf.function]\n",
      "  (https://www.tensorflow.org/guide/intro_to_graphs).\n",
      "\n",
      "  See [Better Performance with tf.function]\n",
      "  (https://www.tensorflow.org/guide/function) for tips on performance and\n",
      "  known limitations.\n",
      "\n",
      "  Example usage:\n",
      "\n",
      "  >>> @tf.function\n",
      "  ... def f(x, y):\n",
      "  ...   return x ** 2 + y\n",
      "  >>> x = tf.constant([2, 3])\n",
      "  >>> y = tf.constant([3, -2])\n",
      "  >>> f(x, y)\n",
      "  <tf.Tensor: ... numpy=array([7, 7], ...)>\n",
      "\n",
      "  The trace-compilation allows non-TensorFlow operations to execute, but under\n",
      "  special conditions. In general, only TensorFlow operations are guaranteed to\n",
      "  run and create fresh results whenever the `GenericFunction` is called.\n",
      "\n",
      "  ## Features\n",
      "\n",
      "  `func` may use data-dependent Python control flow statements, including `if`,\n",
      "  `for`, `while` `break`, `continue` and `return`:\n",
      "\n",
      "  >>> @tf.function\n",
      "  ... def f(x):\n",
      "  ...   if tf.reduce_sum(x) > 0:\n",
      "  ...     return x * x\n",
      "  ...   else:\n",
      "  ...     return -x // 2\n",
      "  >>> f(tf.constant(-2))\n",
      "  <tf.Tensor: ... numpy=1>\n",
      "\n",
      "  `func`'s closure may include `tf.Tensor` and `tf.Variable` objects:\n",
      "\n",
      "  >>> @tf.function\n",
      "  ... def f():\n",
      "  ...   return x ** 2 + y\n",
      "  >>> x = tf.constant([-2, -3])\n",
      "  >>> y = tf.Variable([3, -2])\n",
      "  >>> f()\n",
      "  <tf.Tensor: ... numpy=array([7, 7], ...)>\n",
      "\n",
      "  `func` may also use ops with side effects, such as `tf.print`, `tf.Variable`\n",
      "  and others:\n",
      "\n",
      "  >>> v = tf.Variable(1)\n",
      "  >>> @tf.function\n",
      "  ... def f(x):\n",
      "  ...   for i in tf.range(x):\n",
      "  ...     v.assign_add(i)\n",
      "  >>> f(3)\n",
      "  >>> v\n",
      "  <tf.Variable ... numpy=4>\n",
      "\n",
      "  Important: Any Python side-effects (appending to a list, printing with\n",
      "  `print`, etc) will only happen once, when `func` is traced. To have\n",
      "  side-effects executed into your `tf.function` they need to be written\n",
      "  as TF ops:\n",
      "\n",
      "  >>> l = []\n",
      "  >>> @tf.function\n",
      "  ... def f(x):\n",
      "  ...   for i in x:\n",
      "  ...     l.append(i + 1)    # Caution! Will only happen once when tracing\n",
      "  >>> f(tf.constant([1, 2, 3]))\n",
      "  >>> l\n",
      "  [<tf.Tensor ...>]\n",
      "\n",
      "  Instead, use TensorFlow collections like `tf.TensorArray`:\n",
      "\n",
      "  >>> @tf.function\n",
      "  ... def f(x):\n",
      "  ...   ta = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
      "  ...   for i in range(len(x)):\n",
      "  ...     ta = ta.write(i, x[i] + 1)\n",
      "  ...   return ta.stack()\n",
      "  >>> f(tf.constant([1, 2, 3]))\n",
      "  <tf.Tensor: ..., numpy=array([2, 3, 4], ...)>\n",
      "\n",
      "  ## `tf.function` creates polymorphic callables\n",
      "\n",
      "  Internally, `tf.types.experimental.GenericFunction` may contain multiple\n",
      "  `tf.types.experimental.ConcreteFunction`s, each specialized to arguments with\n",
      "  different data types or shapes, since TensorFlow can perform more\n",
      "  optimizations on graphs of specific shapes, dtypes and values of constant\n",
      "  arguments. `tf.function` treats any pure Python values as opaque objects (best\n",
      "  thought of as compile-time constants), and builds a separate `tf.Graph` for\n",
      "  each set of Python arguments that it encounters.\n",
      "  For more information, see the\n",
      "  [tf.function guide](https://www.tensorflow.org/guide/function#rules_of_tracing)\n",
      "\n",
      "  Executing a `GenericFunction` will select and execute the appropriate\n",
      "  `ConcreteFunction` based on the argument types and values.\n",
      "\n",
      "  To obtain an individual `ConcreteFunction`, use the\n",
      "  `GenericFunction.get_concrete_function` method. It can be called with the\n",
      "  same arguments as `func` and returns a\n",
      "  `tf.types.experimental.ConcreteFunction`. `ConcreteFunction`s are backed by a\n",
      "  single `tf.Graph`:\n",
      "\n",
      "  >>> @tf.function\n",
      "  ... def f(x):\n",
      "  ...   return x + 1\n",
      "  >>> isinstance(f.get_concrete_function(1).graph, tf.Graph)\n",
      "  True\n",
      "\n",
      "  `ConcreteFunction`s can be executed just like `GenericFunction`s, but their\n",
      "  input is resticted to the types to which they're specialized.\n",
      "\n",
      "  ## Retracing\n",
      "\n",
      "  `ConcreteFunctions` are built (traced) on the fly, as the `GenericFunction` is\n",
      "  called with new TensorFlow types or shapes, or with new Python values as\n",
      "  arguments. When `GenericFunction` builds a new trace, it is said that `func`\n",
      "  is retraced. Retracing is a frequent performance concern for `tf.function` as\n",
      "  it can be considerably slower than executing a graph that's already been\n",
      "  traced. It is ideal to minimize the amount of retracing in your code.\n",
      "\n",
      "  Caution: Passing python scalars or lists as arguments to `tf.function` will\n",
      "  usually retrace. To avoid this, pass numeric arguments as Tensors whenever\n",
      "  possible:\n",
      "\n",
      "  >>> @tf.function\n",
      "  ... def f(x):\n",
      "  ...   return tf.abs(x)\n",
      "  >>> f1 = f.get_concrete_function(1)\n",
      "  >>> f2 = f.get_concrete_function(2)  # Slow - compiles new graph\n",
      "  >>> f1 is f2\n",
      "  False\n",
      "  >>> f1 = f.get_concrete_function(tf.constant(1))\n",
      "  >>> f2 = f.get_concrete_function(tf.constant(2))  # Fast - reuses f1\n",
      "  >>> f1 is f2\n",
      "  True\n",
      "\n",
      "  Python numerical arguments should only be used when they take few distinct\n",
      "  values, such as hyperparameters like the number of layers in a neural network.\n",
      "\n",
      "  ## Input signatures\n",
      "\n",
      "  For Tensor arguments, `GenericFunction`creates a new `ConcreteFunction` for\n",
      "  every unique set of input shapes and datatypes. The example below creates two\n",
      "  separate `ConcreteFunction`s, each specialized to a different shape:\n",
      "\n",
      "  >>> @tf.function\n",
      "  ... def f(x):\n",
      "  ...   return x + 1\n",
      "  >>> vector = tf.constant([1.0, 1.0])\n",
      "  >>> matrix = tf.constant([[3.0]])\n",
      "  >>> f.get_concrete_function(vector) is f.get_concrete_function(matrix)\n",
      "  False\n",
      "\n",
      "  An \"input signature\" can be optionally provided to `tf.function` to control\n",
      "  this process. The input signature specifies the shape and type of each\n",
      "  Tensor argument to the function using a `tf.TensorSpec` object. More general\n",
      "  shapes can be used. This ensures only one `ConcreteFunction` is created, and\n",
      "  restricts the `GenericFunction` to the specified shapes and types. It is\n",
      "  an effective way to limit retracing when Tensors have dynamic shapes.\n",
      "\n",
      "  >>> @tf.function(\n",
      "  ...     input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])\n",
      "  ... def f(x):\n",
      "  ...   return x + 1\n",
      "  >>> vector = tf.constant([1.0, 1.0])\n",
      "  >>> matrix = tf.constant([[3.0]])\n",
      "  >>> f.get_concrete_function(vector) is f.get_concrete_function(matrix)\n",
      "  True\n",
      "\n",
      "  ## Variables may only be created once\n",
      "\n",
      "  `tf.function` only allows creating new `tf.Variable` objects when it is called\n",
      "  for the first time:\n",
      "\n",
      "  >>> class MyModule(tf.Module):\n",
      "  ...   def __init__(self):\n",
      "  ...     self.v = None\n",
      "  ...\n",
      "  ...   @tf.function\n",
      "  ...   def __call__(self, x):\n",
      "  ...     if self.v is None:\n",
      "  ...       self.v = tf.Variable(tf.ones_like(x))\n",
      "  ...     return self.v * x\n",
      "\n",
      "  In general, it is recommended to create `tf.Variable`s outside of\n",
      "  `tf.function`.\n",
      "  In simple cases, persisting state across `tf.function` boundaries may be\n",
      "  implemented using a pure functional style in which state is represented by\n",
      "  `tf.Tensor`s passed as arguments and returned as return values.\n",
      "\n",
      "  Contrast the two styles below:\n",
      "\n",
      "  >>> state = tf.Variable(1)\n",
      "  >>> @tf.function\n",
      "  ... def f(x):\n",
      "  ...   state.assign_add(x)\n",
      "  >>> f(tf.constant(2))  # Non-pure functional style\n",
      "  >>> state\n",
      "  <tf.Variable ... numpy=3>\n",
      "\n",
      "  >>> state = tf.constant(1)\n",
      "  >>> @tf.function\n",
      "  ... def f(state, x):\n",
      "  ...   state += x\n",
      "  ...   return state\n",
      "  >>> state = f(state, tf.constant(2))  # Pure functional style\n",
      "  >>> state\n",
      "  <tf.Tensor: ... numpy=3>\n",
      "\n",
      "  ## Python operations execute only once per trace\n",
      "\n",
      "  `func` may contain TensorFlow operations mixed with pure Python operations.\n",
      "  However, when the function is executed, only the TensorFlow operations will\n",
      "  run. The Python operations run only once, at trace time. If TensorFlow\n",
      "  operations depend on results from Python operations, those results will be\n",
      "  frozen into the graph.\n",
      "\n",
      "  >>> @tf.function\n",
      "  ... def f(a, b):\n",
      "  ...   print('this runs at trace time; a is', a, 'and b is', b)\n",
      "  ...   return b\n",
      "  >>> f(1, tf.constant(1))\n",
      "  this runs at trace time; a is 1 and b is Tensor(\"...\", shape=(), dtype=int32)\n",
      "  <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "\n",
      "  >>> f(1, tf.constant(2))\n",
      "  <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "\n",
      "  >>> f(2, tf.constant(1))\n",
      "  this runs at trace time; a is 2 and b is Tensor(\"...\", shape=(), dtype=int32)\n",
      "  <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "\n",
      "  >>> f(2, tf.constant(2))\n",
      "  <tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "\n",
      "  Args:\n",
      "    func: The function to be compiled. If `func` is None, `tf.function` returns\n",
      "      a decorator that can be invoked with a single argument - `func`. In other\n",
      "      words, `tf.function(input_signature=...)(func)` is equivalent to\n",
      "      `tf.function(func, input_signature=...)`. The former can be used as\n",
      "      decorator.\n",
      "    input_signature: A possibly nested sequence of `tf.TensorSpec` objects\n",
      "      specifying the shapes and dtypes of the Tensors that will be supplied to\n",
      "      this function. If `None`, a separate function is instantiated for each\n",
      "      inferred input signature.  If input_signature is specified, every input to\n",
      "      `func` must be a `Tensor`, and `func` cannot accept `**kwargs`.\n",
      "    autograph: Whether autograph should be applied on `func` before tracing a\n",
      "      graph. Data-dependent Python control flow statements require\n",
      "      `autograph=True`. For more information, see the\n",
      "      [tf.function and AutoGraph guide](\n",
      "      https://www.tensorflow.org/guide/function#autograph_transformations).\n",
      "    jit_compile: If `True`, compiles the function using\n",
      "      [XLA](https://tensorflow.org/xla). XLA performs compiler optimizations,\n",
      "      such as fusion, and attempts to emit more efficient code. This may\n",
      "      drastically improve the performance. If set to `True`,\n",
      "      the whole function needs to be compilable by XLA, or an\n",
      "      `errors.InvalidArgumentError` is thrown.\n",
      "      If `None` (default), compiles the function with XLA when running on TPU\n",
      "      and goes through the regular function execution path when running on\n",
      "      other devices.\n",
      "      If `False`, executes the function without XLA compilation.  Set this value\n",
      "      to `False` when directly running a multi-device function on TPUs (e.g. two\n",
      "      TPU cores, one TPU core and its host CPU).\n",
      "      Not all functions are compilable, see a list of\n",
      "      [sharp corners](https://tensorflow.org/xla/known_issues).\n",
      "    reduce_retracing: When True, `tf.function` attempts to reduce the\n",
      "      amount of retracing, for example by using more generic shapes. This\n",
      "      can be controlled for user objects by customizing their associated\n",
      "      `tf.types.experimental.TraceType`.\n",
      "    experimental_implements: If provided, contains a name of a \"known\" function\n",
      "      this implements. For example \"mycompany.my_recurrent_cell\".\n",
      "      This is stored as an attribute in inference function,\n",
      "      which can then be detected when processing serialized function.\n",
      "      See [standardizing composite ops](https://github.com/tensorflow/community/blob/master/rfcs/20190610-standardizing-composite_ops.md)  # pylint: disable=line-too-long\n",
      "      for details.  For an example of utilizing this attribute see this\n",
      "      [example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/prepare_composite_functions_tf.cc)\n",
      "      The code above automatically detects and substitutes function that\n",
      "      implements \"embedded_matmul\" and allows TFLite to substitute its own\n",
      "      implementations. For instance, a tensorflow user can use this\n",
      "       attribute to mark that their function also implements\n",
      "      `embedded_matmul` (perhaps more efficiently!)\n",
      "      by specifying it using this parameter:\n",
      "      `@tf.function(experimental_implements=\"embedded_matmul\")`\n",
      "      This can either be specified as just the string name of the function or\n",
      "      a NameAttrList corresponding to a list of key-value attributes associated\n",
      "      with the function name. The name of the function will be in the 'name'\n",
      "      field of the NameAttrList. To define a formal TF op for this function\n",
      "      implements, try the experimental [composite TF](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tfr)\n",
      "      project.\n",
      "    experimental_autograph_options: Optional tuple of\n",
      "      `tf.autograph.experimental.Feature` values.\n",
      "    experimental_relax_shapes: Deprecated. Use `reduce_retracing`\n",
      "      instead.\n",
      "    experimental_compile: Deprecated alias to 'jit_compile'.\n",
      "    experimental_follow_type_hints: Deprecated. Please use input_signature or\n",
      "      reduce_retracing instead.\n",
      "\n",
      "  Returns:\n",
      "     If `func` is not None, returns a `tf.types.experimental.GenericFunction`.\n",
      "     If `func` is None, returns a decorator that, when invoked with a single\n",
      "     `func` argument, returns a `tf.types.experimental.GenericFunction`.\n",
      "\n",
      "  Raises:\n",
      "     `ValueError` when attempting to use `jit_compile=True`, but XLA support is\n",
      "     not available.\n",
      "  \"\"\"\n",
      "  if jit_compile is None and JIT_COMPILE_FUNCTIONS:\n",
      "    jit_compile = True\n",
      "\n",
      "  # TODO(b/224808187): Remove after renaming usages.\n",
      "  if experimental_relax_shapes:\n",
      "    reduce_retracing = True\n",
      "\n",
      "  def decorated(inner_function):\n",
      "    try:\n",
      "      name = inner_function.__name__\n",
      "    except AttributeError:\n",
      "      name = \"function\"\n",
      "    return tf_decorator.make_decorator(\n",
      "        inner_function,\n",
      "        decorator_name=\"tf.function\",\n",
      "        decorator_func=Function(\n",
      "            inner_function,\n",
      "            name,\n",
      "            input_signature=input_signature,\n",
      "            autograph=autograph,\n",
      "            experimental_autograph_options=experimental_autograph_options,\n",
      "            reduce_retracing=reduce_retracing,\n",
      "\n",
      "            # TODO(b/171825496): Update once `experimental_compile` is removed\n",
      "            # entirely in favor of 'jit_compile'.\n",
      "            jit_compile=deprecation.deprecated_argument_lookup(\n",
      "                \"jit_compile\",\n",
      "                jit_compile,\n",
      "                \"experimental_compile\",\n",
      "                experimental_compile),\n",
      "            experimental_implements=experimental_implements))\n",
      "\n",
      "  # This code path is for the `foo = tf.function(foo, ...)` use case\n",
      "  if func is not None:\n",
      "    return decorated(func)\n",
      "\n",
      "  # This code path is for the\n",
      "  #\n",
      "  # @tf.function(...)\n",
      "  # def foo(...):\n",
      "  #    ...\n",
      "  #\n",
      "  # use case, which is equivalent to `foo = tf.function(...)(foo)`\n",
      "  return decorated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(tf.function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4cec6812-96dc-4c28-b3c1-79baa7f96526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decorator\n",
    "# 이 기능만 제외하고 만들기\n",
    "# decorator를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b025e5d-1c2f-4baf-8d72-1b5fd09ba575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#__getitem__ : sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7728cf98-7a0b-4662-966d-ac61c4266ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __getitem__(self, x): #어떤애를 특정했을 때 아이템을 반환하는것 - duck typing\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "152ff06d-dd27-4ec2-bd2b-a5cff890fee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = A()\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5212975-7579-4cb6-9402-2b5d94770529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "class A(Sequence):\n",
    "    pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa37d285-fecb-46ed-8366-a515514af917",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class A with abstract methods __getitem__, __len__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mA\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't instantiate abstract class A with abstract methods __getitem__, __len__"
     ]
    }
   ],
   "source": [
    "a = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2769ae4d-57af-4395-89d5-5341bd56da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70bb1de3-6dd7-4607-8385-acf777fb3bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(ABC):\n",
    "    @abstractmethod\n",
    "    def __getitem(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0429f236-502e-4019-acb6-e4b48febabc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class B with abstract method _B__getitem",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mB\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't instantiate abstract class B with abstract method _B__getitem"
     ]
    }
   ],
   "source": [
    "b = B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f9cd4-c050-4ae9-adc9-57ea853964d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
