{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80e8e4-ba23-417c-a4bf-aaba62a3871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "XML\n",
    "<root>\n",
    "    <node name='a'>1</node>\n",
    "</root>\n",
    "\n",
    "response.headers[content-type] = text/html; charset=encoding\n",
    "response.content(bytes) => text.decode(encoding)\n",
    "respose.text = '<tag>문자열 아니라</tag>', response.encoding ?\n",
    "\n",
    "HyperText(HTML => Not well-formed)\n",
    "Book1       Book2     Book3\n",
    "            - ch7 ---> - ch10\n",
    "-ch1 ----------------> - ch10\n",
    "       HyperLink\n",
    "<a 속성키=속성값></a>\n",
    "<a href= k=v k=v...></a>\n",
    "re.compile(r'<a\\w+ref=(.+?)>(.+?)</a>') => 쉽지 않음.\n",
    "\n",
    "HTML 구조화 된 문서 => 구조화 => DOM(Document Object Model) => Tree(부모를 공유, 항상 1명의 부모를)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb34449-c5b6-4c28-afc1-702f34eb2586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d456dd96-ebf2-4de7-bf0b-f6fc9b1802bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc79b7-5a6c-4c27-b473-788c4e883039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "197ff1d3-ab61-4d75-8317-0e15773e0e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1faeb8f6-147a-475c-bbe3-7a7d86a46258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5f2804-c52f-4459-af7d-a1c4c915ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da653e0e-3f64-4efb-ae12-12d0e1880519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a49d7c6-47ae-485d-9d2c-06f37d27943c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 'text/html')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from requests import request\n",
    "url = 'https://pythonscraping.com/pages/page3.html'\n",
    "resp = request('get', url)\n",
    "resp.status_code, resp.headers['content-type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf69745-4424-4b87-bed1-3d0baf1f4f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img', 'h1', 'div', 'table', 'div']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.text #<= text로 구성된 HTML\n",
    "dom = BeautifulSoup(resp.text, 'html.parser') # <= tree로 구성된 HTML\n",
    "[el.name for el in dom.body.find().find_all(recursive=False)]\n",
    "#Document\n",
    "#  HTML\n",
    "#        BODY\n",
    "#         div\n",
    "#  img  h1   div   table   div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109aa75-d80e-4ac5-97cb-1cd4ef811275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "029bcb97-8938-454c-bc47-7d23c008dc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img', 'h1', 'div', 'table', 'div']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom = BeautifulSoup(resp.text, 'lxml')\n",
    "[el.name for el in dom.body.find().find_all(recursive=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "631117d2-9681-4378-bc95-a0f2877b31f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Server': 'nginx', 'Date': 'Thu, 13 Mar 2025 01:48:54 GMT', 'Content-Type': 'text/html', 'Content-Length': '2405', 'Last-Modified': 'Sat, 09 Jun 2018 19:15:59 GMT', 'Connection': 'keep-alive', 'ETag': '\"5b1c276f-965\"', 'X-Powered-By': 'PleskLin', 'Accept-Ranges': 'bytes'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c89d2ea4-a0bc-482e-a1f9-e0375560acf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_previous_sibling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m footer \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfooter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfooter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_previous_sibling\u001b[49m()\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m      8\u001b[0m     img \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m'\u001b[39m, recursive \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mfind()\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(img\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mhas_attr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_previous_sibling'"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "footer = soup.find('footer')\n",
    "\n",
    "for row in footer.find_previous_sibling().find_all('tr')[1:]:\n",
    "    img = row.find_all('td', recursive =False)[-1].find()\n",
    "    print(img.attrs['src'] if img.has_attr('src') else None)\n",
    "    nurl = urljoin(url, img.attrs['src'])\n",
    "    resp = request('get', nurl)\n",
    "    file = re.search(r'/(^/]+)$', resp.request.url).group(1)\n",
    "    ext = re.search(r'image/(.+);?', resp.headers['content-type'])/group(1)\n",
    "    fp = open(file+'.'+ext, 'wb')\n",
    "    fp.write(resp.content)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff0379-2834-4680-a26f-c8938504ce46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4039819e-85ff-4f62-9180-5ac4fcf51c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "footer.find_previous_sibling().find_all('td', string=re.compile(r^\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d8fe0-61cc-4a07-8131-2f72268effe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa798f-7c31-498c-8621-b9437f618e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.scrapingcourse.com/table-parsing\n",
    "# 1. table 노드를 찾아야 하고\n",
    "# 2. price만 깔끔하게 15개 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0371687f-b75d-4ff3-8b6b-089c859c5b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$999.99\n",
      "$599.99\n",
      "$149.99\n",
      "$79.99\n",
      "$89.99\n",
      "$249.99\n",
      "$39.99\n",
      "$29.99\n",
      "$24.99\n",
      "$34.99\n",
      "$79.99\n",
      "$49.99\n",
      "$59.99\n",
      "$129.99\n",
      "$399.99\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1. 웹페이지 요청\n",
    "url = \"https://www.scrapingcourse.com/table-parsing\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # 응답 에러 확인\n",
    "\n",
    "# 2. HTML 파싱\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# 3. 첫 번째 테이블 찾기\n",
    "table = soup.find(\"table\")\n",
    "if not table:\n",
    "    raise ValueError(\"테이블을 찾을 수 없습니다.\")\n",
    "\n",
    "# 4. 테이블에서 모든 행(row) 가져오기\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "# 5. Price 열의 데이터만 추출\n",
    "prices = []\n",
    "for row in rows[1:]:  # 첫 번째 행은 헤더이므로 제외\n",
    "    cols = row.find_all(\"td\")  # 모든 열 가져오기\n",
    "    if len(cols) > 3:  # Price가 4번째 열(인덱스 3)에 있다고 가정\n",
    "        price = cols[3].text.strip()\n",
    "        prices.append(price)\n",
    "\n",
    "# 6. 상위 15개 출력\n",
    "for price in prices:\n",
    "    print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0198a566-192c-4ed5-b088-c7fea0eae83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.scrapingcourse.com/table-parsing\"\n",
    "dom = BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4b229-7527-4f06-8c97-8cd7f00b8c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
